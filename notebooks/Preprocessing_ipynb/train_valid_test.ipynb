{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we have taken train_df_energy_final.pkl which is the combination of train_df_part_1.pkl and lags_df_1.pkl and splitted it into 3 parts with 80-20-20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory for top level folder\n",
    "dir_ = \"/home/sugam/Work/20-29 Deep Learning/22 Projects/Optimization of Energy Using AIML\"\n",
    "\n",
    "processed_data_dir = dir_+'/data/Processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_pickle(processed_data_dir + \"train_df_energy_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Basic Level Preprocessing\n",
    "df.rename(columns = {\"load_x\":\"load\"},inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "# Making year as 0, 1,....2 instead of 2018, 2019 , 2020\n",
    "df[\"year\"] = df[\"year\"]-df[\"year\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset using fixed split 80% into training and 20% into testing\n",
    "train_size = int(len(df) * 0.8)\n",
    "valid_size = int(len(df[train_size:])*0.5) + train_size\n",
    "train_data, validation_data, test_data = df[:train_size], df[train_size:valid_size], df[valid_size:]\n",
    "target_columns = [\"load\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data (82437, 51)\n",
      "Size of validation data (10305, 51)\n",
      "Size of testing data (10305, 51)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of training data {train_data.shape}\")\n",
    "print(f\"Size of validation data {validation_data.shape}\")\n",
    "print(f\"Size of testing data {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(processed_data_dir+ \"train.csv\",index=False)\n",
    "validation_data.to_csv(processed_data_dir+ \"validation.csv\",index=False)\n",
    "test_data.to_csv(processed_data_dir+ \"test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
