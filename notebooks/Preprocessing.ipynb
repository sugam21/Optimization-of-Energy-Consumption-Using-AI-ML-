{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fc1b08-3027-4ee3-890f-94bc9a340b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory for top level folder\n",
    "dir_ = \"/home/sugam/Work/20-29 Deep Learning/22 Projects/Optimization of Energy Using AIML/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef710429-6851-4aac-b0e1-64778c010be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = dir_ + 'raw/'\n",
    "processed_data_dir = dir_+'Processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d81b8c-30c9-499d-b610-44c70163dfc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. MAIN SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb21b540-aa31-4274-8b06-320a9c2aac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genderal imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc,time,warnings,pickle,psutil,random\n",
    "from math import ceil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3403cf-2d1e-465d-9f47-6e05be073a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# MEMORY PROFILER\n",
    "## Displays memory used by dataframe\n",
    "\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812207c8-07fd-4a8f-9e6d-cfe0f19c3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## MEMORY REDUCER\n",
    "## Function which checks each column and manage the dtype automatically\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print(f'Mem. usage decreased to {end_mem:5.2f} Mb {(100 * (start_mem - end_mem) / start_mem):.1f}% reduction')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a56aa68-30d0-4ef8-8c93-d8c629ce7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging by concat to not lose dtypes\n",
    "def merge_by_concat(df1,df2,merge_on):\n",
    "    merged_df = df1[merge_on] # merge_on is multiple columns\n",
    "    merged_df = merged_df.merge(df2,on=merge_on,how='left')\n",
    "    new_columns = [col for col in list(merged_df) if col not in merge_on]\n",
    "    df1 = pd.concat([df1,merged_df[new_columns]],axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4758eef2-d942-47b9-944d-a0f6ef4e8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Vars\n",
    "###################################################################\n",
    "TARGET = [\"Load_NW\",\"Load_SW\"] # main target ->  Total Load of North Wing (Load_NW), Total Load of South Wing (Load_SW)\n",
    "END_TRAIN = '2020-12-04 23:45:00' # Last day of train set\n",
    "MAIN_INDEX = ['date'] # Identify each entry by these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81b0cc-c1f0-46b4-be7d-0bea5e9594f5",
   "metadata": {},
   "source": [
    "# 2. PART -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1de8ca2-b6a6-4136-85a8-8f5e716218f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Load Main Data\n",
      "✅ Load Main Data\n"
     ]
    }
   ],
   "source": [
    "####################### LOAD DATA\n",
    "##################################################################\n",
    "print(\"⏳ Load Main Data\")\n",
    "\n",
    "# Refering our data without any modification and dtype\n",
    "train_df = pd.read_csv(processed_data_dir+'merged_file.csv',\n",
    "                       header=1,\n",
    "                       index_col=0,\n",
    "                       parse_dates = True)\n",
    "\n",
    "train_df.drop(\"Unnamed: 6\", \n",
    "              axis=1,\n",
    "              inplace=True) # Garbage column\n",
    "\n",
    "#train_df.drop_duplicates(subset='date',inplace=True)\n",
    "\n",
    "train_df.index = pd.to_datetime(train_df.index,format='mixed',dayfirst=True) # Converting index to date time format\n",
    "\n",
    "print(\"✅ Load Main Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc5419d-2ac8-4182-905e-e1fd63686898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64672, 114)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc5c2ca4-05fd-4b02-a984-f37a91f1da13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if the index is unique or not :  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if the index is unique or not : \",str(len(pd.unique(train_df.index))) == train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3953c90-733c-45f7-9b71-6d6e9e1cd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54b32f2-0715-47f6-bbd7-88066fa36ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all North wings and South wing load into a single variables\n",
    "\n",
    "train_df[\"Load_SW\"] = (train_df['Miscellaneous electric load for the South Wing']+\n",
    "                       train_df['Lighting load for the South Wing']+\n",
    "                       train_df['Heating Ventilation and Air Conditioning load for the South Wing']\n",
    "                      )\n",
    "\n",
    "train_df.drop(['Miscellaneous electric load for the South Wing',\n",
    "               'Lighting load for the South Wing',\n",
    "               'Heating Ventilation and Air Conditioning load for the South Wing']\n",
    "              ,axis=1,\n",
    "             inplace=True)\n",
    "\n",
    "train_df[\"Load_NW\"] = (train_df['Miscellaneous electric load for the North Wing']+\n",
    "                       train_df['Heating Ventilation and Air Conditioning load for the Nouth Wing']\n",
    "                      )\n",
    "\n",
    "train_df.drop(['Miscellaneous electric load for the North Wing',\n",
    "               'Heating Ventilation and Air Conditioning load for the Nouth Wing']\n",
    "              ,axis=1,\n",
    "             inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf98b414-d000-49f6-a831-7a8e4bb56a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum(axis=0)[train_df.isnull().sum(axis=0)>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c006934f-ebfb-46b3-9acc-c552f4d53484",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_columns = train_df.isnull().sum(axis=0)[train_df.isnull().sum(axis=0)>0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f0a57a-35ea-4a44-8eee-b2b87c3f125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(\"bfill\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fa107f-45fb-4516-a54c-4cc1f1c524d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating month and year columns\n",
    "# train_df[\"year\"] = train_df.index.year\n",
    "# train_df[\"month\"] = train_df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e61045a0-b6c7-45a6-9e3f-c1749a583ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in na_columns:\n",
    "#     temp = pd.DataFrame()\n",
    "#     temp = train_df.groupby([\"year\",\"month\"])[col].agg('mean').reset_index()\n",
    "#     temp.rename(columns={col: \"mean_column\"},inplace=True)\n",
    "#     temp = pd.merge(train_df,temp,how=\"left\",on=[\"year\",\"month\"])\n",
    "#     temp.loc[temp[col].isna(),[col]] = temp[\"mean_column\"]\n",
    "\n",
    "# temp.isna().sum(axis=0)[temp.isna().sum(axis=0)>0]\n",
    "# #train_df[na_columns] = temp[na_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb2c0687-bef1-4778-a0db-a5106702d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = pd.DataFrame()\n",
    "# for col in na_columns[:]:\n",
    "#     temp = train_df.groupby([\"year\",\"month\"])[col].agg('mean').reset_index()\n",
    "#     temp.rename(columns={col: \"mean_column\"},inplace=True)\n",
    "#     temp = pd.merge(train_df,temp,how=\"left\",on=[\"year\",\"month\"])\n",
    "#     temp.loc[temp[col].isna(),col] = temp[\"mean_column\"]\n",
    "#     print(temp[col].isna().sum())\n",
    "# temp.isna().sum(axis=0)\n",
    "# train_df[na_columns] = temp[na_columns]\n",
    "# train_df.isna().sum(axis=0)[train_df.isna().sum(axis=0)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4565401-15b4-4f94-bb60-7b75d037fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to make predictions, it's essential to incorporate the test set into our dataframe. \n",
    "# The following code is responsible for appending new rows to accommodate future data.\n",
    "# We are going to predict the probable data for next 24 hour(in future) in time interval of 15 min\n",
    "# 24*60 (minutes in a day) / 15 = 96 (15's in 24 hour)\n",
    "for i in range(1,97):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90cee186-3903-4ead-9f59-a51abb251c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heat pump heating water supply temperature</th>\n",
       "      <th>Roof Top Unit * supply air temperature setpoint_001</th>\n",
       "      <th>Roof Top Unit * supply air temperature setpoint_002</th>\n",
       "      <th>Roof Top Unit * supply air temperature setpoint_003</th>\n",
       "      <th>Roof Top Unit * supply air temperature setpoint_004</th>\n",
       "      <th>Roof Top Unit * supply air temperature_001</th>\n",
       "      <th>Roof Top Unit * supply air temperature_002</th>\n",
       "      <th>Roof Top Unit * supply air temperature_003</th>\n",
       "      <th>Roof Top Unit * supply air temperature_004</th>\n",
       "      <th>Roof Top Unit * return air temperature_001</th>\n",
       "      <th>...</th>\n",
       "      <th>Zone temperature of exterior zone065</th>\n",
       "      <th>Zone temperature of exterior zone066</th>\n",
       "      <th>Zone temperature of exterior zone067</th>\n",
       "      <th>Zone temperature of exterior zone068</th>\n",
       "      <th>Zone temperature of exterior zone069</th>\n",
       "      <th>Zone temperature of exterior zone070</th>\n",
       "      <th>Zone temperature of exterior zone071</th>\n",
       "      <th>Zone temperature of exterior zone072</th>\n",
       "      <th>Load_SW</th>\n",
       "      <th>Load_NW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-05 10:45:00</th>\n",
       "      <td>123.2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.9</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>67.7</td>\n",
       "      <td>69.6</td>\n",
       "      <td>...</td>\n",
       "      <td>69.7</td>\n",
       "      <td>68.8</td>\n",
       "      <td>70.9</td>\n",
       "      <td>69.7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>24.434211</td>\n",
       "      <td>9.77806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05 11:00:00</th>\n",
       "      <td>123.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>67.9</td>\n",
       "      <td>66.4</td>\n",
       "      <td>67.7</td>\n",
       "      <td>69.5</td>\n",
       "      <td>...</td>\n",
       "      <td>69.7</td>\n",
       "      <td>68.8</td>\n",
       "      <td>70.8</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.9</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>23.813333</td>\n",
       "      <td>8.981637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05 11:15:00</th>\n",
       "      <td>124.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>68.5</td>\n",
       "      <td>65.2</td>\n",
       "      <td>67.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>...</td>\n",
       "      <td>69.7</td>\n",
       "      <td>68.7</td>\n",
       "      <td>70.8</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.9</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25.387218</td>\n",
       "      <td>8.208946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05 11:30:00</th>\n",
       "      <td>122.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>67.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>69.6</td>\n",
       "      <td>68.7</td>\n",
       "      <td>70.7</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.4</td>\n",
       "      <td>69.3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>24.8375</td>\n",
       "      <td>8.798963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05 11:45:00</th>\n",
       "      <td>122.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.9</td>\n",
       "      <td>68.8</td>\n",
       "      <td>67.1</td>\n",
       "      <td>67.4</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>69.6</td>\n",
       "      <td>68.6</td>\n",
       "      <td>70.6</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.4</td>\n",
       "      <td>69.2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25.025</td>\n",
       "      <td>9.61075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Heat pump heating water supply temperature  \\\n",
       "date                                                              \n",
       "2020-02-05 10:45:00                                       123.2   \n",
       "2020-02-05 11:00:00                                       123.4   \n",
       "2020-02-05 11:15:00                                       124.0   \n",
       "2020-02-05 11:30:00                                       122.9   \n",
       "2020-02-05 11:45:00                                       122.9   \n",
       "\n",
       "                     Roof Top Unit * supply air temperature setpoint_001  \\\n",
       "date                                                                       \n",
       "2020-02-05 10:45:00                                               68.0     \n",
       "2020-02-05 11:00:00                                               68.0     \n",
       "2020-02-05 11:15:00                                               68.0     \n",
       "2020-02-05 11:30:00                                               68.0     \n",
       "2020-02-05 11:45:00                                               68.0     \n",
       "\n",
       "                     Roof Top Unit * supply air temperature setpoint_002  \\\n",
       "date                                                                       \n",
       "2020-02-05 10:45:00                                               68.0     \n",
       "2020-02-05 11:00:00                                               68.0     \n",
       "2020-02-05 11:15:00                                               68.0     \n",
       "2020-02-05 11:30:00                                               68.0     \n",
       "2020-02-05 11:45:00                                               68.0     \n",
       "\n",
       "                     Roof Top Unit * supply air temperature setpoint_003  \\\n",
       "date                                                                       \n",
       "2020-02-05 10:45:00                                               68.0     \n",
       "2020-02-05 11:00:00                                               68.0     \n",
       "2020-02-05 11:15:00                                               68.0     \n",
       "2020-02-05 11:30:00                                               68.0     \n",
       "2020-02-05 11:45:00                                               68.0     \n",
       "\n",
       "                     Roof Top Unit * supply air temperature setpoint_004  \\\n",
       "date                                                                       \n",
       "2020-02-05 10:45:00                                               68.0     \n",
       "2020-02-05 11:00:00                                               68.0     \n",
       "2020-02-05 11:15:00                                               68.0     \n",
       "2020-02-05 11:30:00                                               68.0     \n",
       "2020-02-05 11:45:00                                               68.0     \n",
       "\n",
       "                    Roof Top Unit * supply air temperature_001  \\\n",
       "date                                                             \n",
       "2020-02-05 10:45:00                                       68.9   \n",
       "2020-02-05 11:00:00                                       68.8   \n",
       "2020-02-05 11:15:00                                       68.8   \n",
       "2020-02-05 11:30:00                                       68.9   \n",
       "2020-02-05 11:45:00                                       68.9   \n",
       "\n",
       "                    Roof Top Unit * supply air temperature_002  \\\n",
       "date                                                             \n",
       "2020-02-05 10:45:00                                       69.0   \n",
       "2020-02-05 11:00:00                                       67.9   \n",
       "2020-02-05 11:15:00                                       68.5   \n",
       "2020-02-05 11:30:00                                       68.0   \n",
       "2020-02-05 11:45:00                                       68.8   \n",
       "\n",
       "                    Roof Top Unit * supply air temperature_003  \\\n",
       "date                                                             \n",
       "2020-02-05 10:45:00                                       67.4   \n",
       "2020-02-05 11:00:00                                       66.4   \n",
       "2020-02-05 11:15:00                                       65.2   \n",
       "2020-02-05 11:30:00                                       66.1   \n",
       "2020-02-05 11:45:00                                       67.1   \n",
       "\n",
       "                    Roof Top Unit * supply air temperature_004  \\\n",
       "date                                                             \n",
       "2020-02-05 10:45:00                                       67.7   \n",
       "2020-02-05 11:00:00                                       67.7   \n",
       "2020-02-05 11:15:00                                       67.5   \n",
       "2020-02-05 11:30:00                                       67.2   \n",
       "2020-02-05 11:45:00                                       67.4   \n",
       "\n",
       "                     Roof Top Unit * return air temperature_001  ...  \\\n",
       "date                                                             ...   \n",
       "2020-02-05 10:45:00                                        69.6  ...   \n",
       "2020-02-05 11:00:00                                        69.5  ...   \n",
       "2020-02-05 11:15:00                                        69.5  ...   \n",
       "2020-02-05 11:30:00                                        69.3  ...   \n",
       "2020-02-05 11:45:00                                        69.3  ...   \n",
       "\n",
       "                     Zone temperature of exterior zone065  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  69.7   \n",
       "2020-02-05 11:00:00                                  69.7   \n",
       "2020-02-05 11:15:00                                  69.7   \n",
       "2020-02-05 11:30:00                                  69.6   \n",
       "2020-02-05 11:45:00                                  69.6   \n",
       "\n",
       "                     Zone temperature of exterior zone066  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  68.8   \n",
       "2020-02-05 11:00:00                                  68.8   \n",
       "2020-02-05 11:15:00                                  68.7   \n",
       "2020-02-05 11:30:00                                  68.7   \n",
       "2020-02-05 11:45:00                                  68.6   \n",
       "\n",
       "                     Zone temperature of exterior zone067  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  70.9   \n",
       "2020-02-05 11:00:00                                  70.8   \n",
       "2020-02-05 11:15:00                                  70.8   \n",
       "2020-02-05 11:30:00                                  70.7   \n",
       "2020-02-05 11:45:00                                  70.6   \n",
       "\n",
       "                     Zone temperature of exterior zone068  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  69.7   \n",
       "2020-02-05 11:00:00                                  69.7   \n",
       "2020-02-05 11:15:00                                  69.5   \n",
       "2020-02-05 11:30:00                                  69.5   \n",
       "2020-02-05 11:45:00                                  69.5   \n",
       "\n",
       "                     Zone temperature of exterior zone069  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  70.0   \n",
       "2020-02-05 11:00:00                                  69.9   \n",
       "2020-02-05 11:15:00                                  69.9   \n",
       "2020-02-05 11:30:00                                  69.8   \n",
       "2020-02-05 11:45:00                                  69.8   \n",
       "\n",
       "                     Zone temperature of exterior zone070  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  69.5   \n",
       "2020-02-05 11:00:00                                  69.5   \n",
       "2020-02-05 11:15:00                                  69.5   \n",
       "2020-02-05 11:30:00                                  69.4   \n",
       "2020-02-05 11:45:00                                  69.4   \n",
       "\n",
       "                     Zone temperature of exterior zone071  \\\n",
       "date                                                        \n",
       "2020-02-05 10:45:00                                  69.5   \n",
       "2020-02-05 11:00:00                                  69.4   \n",
       "2020-02-05 11:15:00                                  69.4   \n",
       "2020-02-05 11:30:00                                  69.3   \n",
       "2020-02-05 11:45:00                                  69.2   \n",
       "\n",
       "                     Zone temperature of exterior zone072    Load_SW   Load_NW  \n",
       "date                                                                            \n",
       "2020-02-05 10:45:00                                  71.0  24.434211   9.77806  \n",
       "2020-02-05 11:00:00                                  71.0  23.813333  8.981637  \n",
       "2020-02-05 11:15:00                                  71.0  25.387218  8.208946  \n",
       "2020-02-05 11:30:00                                  71.0    24.8375  8.798963  \n",
       "2020-02-05 11:45:00                                  71.0     25.025   9.61075  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48d0ae6f-596b-47f9-b02c-405a083a1079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-05 12:00:00')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.index[-1]+ pd.Timedelta(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb821f6-1408-43eb-97b5-4623a45b1234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4d40b-d566-4292-bc89-c5aa9a65aafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb24a5c4-a5c4-422a-a276-700cff598450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################### MAKE GRID\n",
    "# ##################################################################\n",
    "# print(\"Create Grid\")\n",
    "\n",
    "# # We are unpivoting the table inorder to convert wide format table into long format\n",
    "# index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "# grid_df = pd.melt(train_df,\n",
    "#                  id_vars = index_columns,\n",
    "#                  var_name = 'd',\n",
    "#                  value_name = TARGET)\n",
    "# # In the train_df, there are very few training rows\n",
    "# # But each day can provide a lot of training data\n",
    "# print(f\"Train rows: {len(train_df)} --- {len(grid_df)}\")\n",
    "\n",
    "# # To be able to make predictions we need to add test set to our grid\n",
    "# # Below code adds the new rows for future data.\n",
    "# # It will add 28 days in the future\n",
    "# add_grid = pd.DataFrame()\n",
    "# for i in range(1,29):\n",
    "#     temp_df = train_df[index_columns]\n",
    "#     temp_df = temp_df.drop_duplicates() # Ensures data is unique which you going to predict in the future\n",
    "#     temp_df['d'] = \"d_\"+str(END_TRAIN+i)\n",
    "#     temp_df[TARGET] = np.nan\n",
    "#     add_grid = pd.concat([add_grid,temp_df])\n",
    "\n",
    "# grid_df = pd.concat([grid_df,add_grid])\n",
    "# grid_df.reset_index(drop=False,inplace=True)\n",
    "# del temp_df, add_grid\n",
    "# del train_df\n",
    "\n",
    "# # Let's check our memory usage\n",
    "# print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "# # We can free some memory \n",
    "# # by converting \"strings\" to categorical\n",
    "# # it will not affect merging and \n",
    "# # we will not lose any valuable data\n",
    "# for col in index_columns:\n",
    "#     grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# # Let's check again memory usage\n",
    "# print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eceeefe-9ca2-43e9-8e68-7ba609ca1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Product Release date\n",
    "# #################################################################################\n",
    "# print('Release week')\n",
    "\n",
    "# # It seems that leadings zero values\n",
    "# # in each train_df item row\n",
    "# # are not real 0 sales but mean\n",
    "# # absence for the item in the store\n",
    "# # we can safe some memory by removing\n",
    "# # such zeros\n",
    "\n",
    "# # Prices are set by week\n",
    "# # so it we will have not very accurate release week \n",
    "# release_df = prices_df.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "# release_df.columns = ['store_id','item_id','release']\n",
    "\n",
    "# # Now we can merge release_df\n",
    "# grid_df = merge_by_concat(grid_df, release_df, ['store_id','item_id'])\n",
    "# del release_df\n",
    "\n",
    "# # We want to remove some \"zeros\" rows\n",
    "# # from grid_df \n",
    "# # to do it we need wm_yr_wk column\n",
    "# # let's merge partly calendar_df to have it\n",
    "# grid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk','d']], ['d'])\n",
    "                      \n",
    "# # Now we can cutoff some rows \n",
    "# # and safe memory \n",
    "# grid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\n",
    "# grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# # Let's check our memory usage\n",
    "# print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# # Should we keep release week \n",
    "# # as one of the features?\n",
    "# # Only good CV can give the answer.\n",
    "# # Let's minify the release values.\n",
    "# # Min transformation will not help here \n",
    "# # as int16 -> Integer (-32768 to 32767)\n",
    "# # and our grid_df['release'].max() serves for int16\n",
    "# # but we have have an idea how to transform other columns in case we will need it\n",
    "# grid_df['release'] = grid_df['release'] - grid_df['release'].min()\n",
    "# grid_df['release'] = grid_df['release'].astype(np.int16)\n",
    "\n",
    "# # Let's check again memory usage\n",
    "# print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cbe192e-3961-4156-9a19-1e961f92717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ########################### Save part 1\n",
    "# #################################################################################\n",
    "# print('Save Part 1')\n",
    "\n",
    "# # We have our BASE grid ready\n",
    "# # and can save it as pickle file\n",
    "# # for future use (model training)\n",
    "# grid_df.to_pickle(processed_data_dir+'grid_part_1.pkl')\n",
    "# print('Size:', grid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa829f33-2d57-42d5-b779-c89cd3895f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################## PRICES\n",
    "# ######################################################\n",
    "# print(\"Prices\")\n",
    "\n",
    "# # We can do some basic aggregration\n",
    "# prices_df['price_max'] = prices_df.groupby([\"store_id\",\"item_id\"])[\"sell_price\"].transform(\"max\") # this gives you the maximum price each unique product has been sold to .\n",
    "# # Same product can be sold to many prices but the above code finds out the maximum price. Finally it replaces each item in that group with the maximum value.\n",
    "# prices_df['price_min'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "# prices_df[\"price_mean\"] = prices_df.groupby([\"store_id\",\"item_id\"])['sell_price'].transform(\"mean\")\n",
    "# prices_df[\"price_std\"] = prices_df.groupby([\"store_id\",\"item_id\"])['sell_price'].transform(\"std\")\n",
    "\n",
    "\n",
    "# # Doing price normalization(min/max scaling)\n",
    "# prices_df[\"price_norm\"] = prices_df[\"sell_price\"]/prices_df[\"price_max\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb8dc39c-6cc6-44f1-b5e9-f215328f4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some items can be inflation dependent and some can be stable\n",
    "# prices_df[\"price_nunique\"] = prices_df.groupby([\"store_id\",\"item_id\"])[\"sell_price\"].transform(\"nunique\")\n",
    "# prices_df[\"item_nuinque\"] = prices_df.groupby([\"store_id\",\"item_id\"])[\"item_id\"].transform(\"nunique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92d4b723-044e-4bb5-addb-38a9f66cc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making rolling aggregations but with months and years as window\n",
    "# calendar_prices = calendar_df[[\"wm_yr_wk\",\"month\",\"year\"]]\n",
    "# calendar_prices = calendar_prices.drop_duplicates(subset=[\"wm_yr_wk\"])\n",
    "# prices_df = prices_df.merge(calendar_prices[[\"wm_yr_wk\",\"month\",\"year\"]],on=[\"wm_yr_wk\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "103a2d72-c6ca-46d9-a1ed-a9d80f7f91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del calendar_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce54bdf5-efe0-491e-97fa-a7ace9febec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we can add price \"momentum\" (some sort of)\n",
    "# # Shifted by week \n",
    "# # by month mean\n",
    "# # by year mean\n",
    "# prices_df['price_momentum'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "# prices_df['price_momentum_m'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "# prices_df['price_momentum_y'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n",
    "\n",
    "# del prices_df['month'], prices_df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8907b5-8661-4705-a544-6c3c866361b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
