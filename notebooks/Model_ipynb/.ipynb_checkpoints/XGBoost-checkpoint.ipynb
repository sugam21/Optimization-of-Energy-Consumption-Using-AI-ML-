{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory for top level folder\n",
    "dir_ = \"/home/sugam/Work/20-29 Deep Learning/22 Projects/Optimization of Energy Using AIML\"\n",
    "\n",
    "processed_data_dir = dir_+'/data/Processed/'\n",
    "model_dir = dir_+'/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "train_df_part_1 = pd.read_pickle(processed_data_dir + \"train_df_part_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week_num</th>\n",
       "      <th>is_weekdend</th>\n",
       "      <th>load_min</th>\n",
       "      <th>load_max</th>\n",
       "      <th>load_mean</th>\n",
       "      <th>load_std</th>\n",
       "      <th>load_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.8125</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.53125</td>\n",
       "      <td>162.0</td>\n",
       "      <td>75.9375</td>\n",
       "      <td>17.234375</td>\n",
       "      <td>0.532950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.6875</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.53125</td>\n",
       "      <td>162.0</td>\n",
       "      <td>75.9375</td>\n",
       "      <td>17.234375</td>\n",
       "      <td>0.532059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.53125</td>\n",
       "      <td>162.0</td>\n",
       "      <td>75.9375</td>\n",
       "      <td>17.234375</td>\n",
       "      <td>0.534570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.1875</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.53125</td>\n",
       "      <td>162.0</td>\n",
       "      <td>75.9375</td>\n",
       "      <td>17.234375</td>\n",
       "      <td>0.528010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.6875</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.53125</td>\n",
       "      <td>162.0</td>\n",
       "      <td>75.9375</td>\n",
       "      <td>17.234375</td>\n",
       "      <td>0.572638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      load  year  month  day  hour  minute  weekday  week_num  is_weekdend  \\\n",
       "0  65.8125  2018      1    1     1       0        0         1            0   \n",
       "1  65.6875  2018      1    1     1      15        0         1            0   \n",
       "2  66.0000  2018      1    1     1      30        0         1            0   \n",
       "3  65.1875  2018      1    1     1      45        0         1            0   \n",
       "4  70.6875  2018      1    1     2       0        0         1            0   \n",
       "\n",
       "   load_min  load_max  load_mean   load_std  load_norm  \n",
       "0  38.53125     162.0    75.9375  17.234375   0.532950  \n",
       "1  38.53125     162.0    75.9375  17.234375   0.532059  \n",
       "2  38.53125     162.0    75.9375  17.234375   0.534570  \n",
       "3  38.53125     162.0    75.9375  17.234375   0.528010  \n",
       "4  38.53125     162.0    75.9375  17.234375   0.572638  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_part_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for remaining NaN values\n",
    "nan_count = train_df_part_1.isna().sum().sum()\n",
    "print(f\"Total NaN values: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset using fixed split 80% into training and 20% into testing\n",
    "train_size = int(len(train_df_part_1) * 0.8)\n",
    "train_data, test_data = train_df_part_1[:train_size], train_df_part_1[train_size:]\n",
    "target_columns = [\"load\"] \n",
    "\n",
    "X_train, y_train = train_data.drop(target_columns, axis=1), train_data[target_columns]\n",
    "X_test, y_test = test_data.drop(target_columns, axis=1), test_data[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train data: (82438, 13)\n",
      "Shape of Test data: (20610, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Train data: {X_train.shape}\")\n",
    "print(f\"Shape of Test data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 9.3037748336792\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_valid)\n",
    "xgb_rmse = mean_squared_error(y_valid, xgb_predictions, squared=False)\n",
    "print(f'XGBoost RMSE: {xgb_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    criterion = trial.suggest_categorical(\"criterion\",[\"gini\",\"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\",2,32,log=True)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,500)\n",
    "    boosters = trial.suggest_categorical(\"boosters\",[\"gbtree\",\"gblinear\",\"dart\"])\n",
    "    eta = trial.suggest_float(\"eta\",0.1,1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\",0.001,1,log=True)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\",1,10)\n",
    "    gamma = trial.suggest_float(\"gamma\",0.0,0.5)\n",
    "    \n",
    "    xgb_model = XGBRegressor(criterion = criterion,\n",
    "                            max_depth = max_depth,\n",
    "                            n_estimator = n_estimators,\n",
    "                            verbosity=1,\n",
    "                            boosters = boosters,\n",
    "                            eta = eta,\n",
    "                            learning_rate = learning_rate,\n",
    "                            min_child_weight = min_child_weight,\n",
    "                            gamma = gamma)\n",
    "    \n",
    "    xgb_model.fit(X_train,y_train)\n",
    "    rmse_score = mean_squared_error(y_train,xgb_model.predict(X_train),squared=False)\n",
    "    return rmse_score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                            study_name=\"xgb_study\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "trial = study.best_trial\n",
    "print(f\"RMSE: {trial.value}\")\n",
    "print(f\"Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 3.1189017295837402\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(criterion='entropy',\n",
    "                         max_depth =  18,\n",
    "                         n_estimators = 173,\n",
    "                         boosters = 'gblinear',\n",
    "                         eta = 0.8321535613093416, \n",
    "                         learning_rate = 0.9327551352534427,\n",
    "                         min_child_weight = 5,\n",
    "                         gamma = 0.0014464638207411923)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_rmse = mean_squared_error(y_test, xgb_predictions, squared=False)\n",
    "print(f'XGBoost RMSE: {xgb_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_dir+'xgb_model_train_df_part_1.bin'\n",
    "pickle.dump(xgb_model, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
